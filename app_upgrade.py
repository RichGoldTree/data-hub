from flask import Flask, render_template_string, request, redirect, Response
import pandas as pd
import os
import json

app = Flask(__name__)

# =========================
# ê¸°ë³¸ ê²½ë¡œ
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
META_FILE = os.path.join(BASE_DIR, "datasets.json")
STANDARD_FILE = os.path.join(BASE_DIR, "example_table2.csv")

os.makedirs(DATA_DIR, exist_ok=True)

# =========================
# í•­ëª© ê·¸ë£¹ ì •ì˜
# =========================
ITEM_GROUPS = {
    "ì¤‘ê¸ˆì†": [
        "Cd(mg/kg)", "Cu(mg/kg)", "As(mg/kg)", "Hg(mg/kg)",
        "Pb(mg/kg)", "Cr6+(mg/kg)", "Zn(mg/kg)", "Ni(mg/kg)"
    ],
    "ìœ ë¥˜": [
        "Benzene", "Toluene", "Ethylbenzene", "Xylene", "TPH"
    ],
    "ìœ ê¸°ìš©ì œ": [
        "TCE", "PCE", "1,2DCA (1,2-ë””í´ë¡œë¡œì—íƒ„)"
    ],
    "ê¸°íƒ€": [
        "F(mg/kg)", "PCBs(mg/kg)", "CN(mg/kg)", "Phenol(mg/kg)",
        "Pentachlorophenol(mg/kg)", "Dioxin", "pH"
    ]
}

# =========================
# CSV ë¡œë”©
# =========================
def read_csv_safe(path):
    try:
        return pd.read_csv(path, encoding="utf-8")
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="cp949")

def normalize_columns(df):
    df.columns = (
        df.columns.astype(str)
        .str.strip()
        .str.replace("\n", "", regex=False)
        .str.replace("\r", "", regex=False)
    )
    return df

# =========================
# ì¡°ì‚¬êµ¬ë¶„ / ì§€ì—­
# =========================
def get_survey_column(df):
    for c in df.columns:
        if "ì¡°ì‚¬êµ¬ë¶„" in c:
            return c
    return None

def normalize_survey_type(v):
    if pd.isna(v):
        return None
    v = str(v)
    if "ê°œí™©" in v:
        return "A"
    if "ì •ë°€" in v or "ìƒì„¸" in v:
        return "B"
    return None

def normalize_region(v):
    if pd.isna(v):
        return None
    v = str(v)
    if "1" in v:
        return "1ì§€ì—­"
    if "2" in v:
        return "2ì§€ì—­"
    if "3" in v:
        return "3ì§€ì—­"
    return None

# =========================
# ìˆ«ì ì •ê·œí™”
# =========================
def normalize_numeric_series(s):
    cleaned = (
        s.astype(str)
         .str.replace("ï¼", "", regex=False)
         .str.replace(r"[^0-9eE\.\+\-]", "", regex=True)
         .str.strip()
         .replace("", pd.NA)
    )
    return pd.to_numeric(cleaned, errors="coerce")

# =========================
# ê¸°ì¤€ ë¡œë”©
# =========================
def load_standards(path):
    df = normalize_columns(read_csv_safe(path))
    standards = {}
    for _, r in df.iterrows():
        region = str(r.iloc[0]).strip()
        criteria_raw = str(r.iloc[1]).strip()
        if not region or not criteria_raw:
            continue
        criteria = "ìš°ë ¤40" if "40" in criteria_raw else "ìš°ë ¤ê¸°ì¤€"
        standards.setdefault(region, {})
        standards[region].setdefault(criteria, {})
        for col in df.columns[2:]:
            standards[region][criteria][col] = r[col]
    return standards

STANDARDS = load_standards(STANDARD_FILE) if os.path.exists(STANDARD_FILE) else {}

# =========================
# ë©”íƒ€ë°ì´í„°
# =========================
def load_datasets():
    if os.path.exists(META_FILE):
        with open(META_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

DATASETS = load_datasets()

# =========================
# ë¶„ì„ ë¡œì§
# =========================
def get_site_series(df):
    if "ì‹œë£Œëª…" in df.columns:
        return df["ì‹œë£Œëª…"].astype(str)
    if "ì§€ì ëª…" in df.columns:
        return df["ì§€ì ëª…"].astype(str)
    return None

def is_exceed(row, item, region):
    v = row[item]
    if pd.isna(v):
        return False
    std = STANDARDS.get(region, {}).get("ìš°ë ¤ê¸°ì¤€", {}).get(item)
    try:
        return v > float(std)
    except:
        return False

def analyze_dataset(df, items):
    site = get_site_series(df)
    out = []

    for item in items:
        r = {"í•­ëª©": item}

        if item not in df.columns:
            for region in ["1ì§€ì—­", "2ì§€ì—­", "3ì§€ì—­"]:
                r[f"{region}_ì§€ì ìˆ˜"] = 0
                r[f"{region}_ìµœê³ "] = None
                r[f"{region}_ìš°ë ¤ì´ˆê³¼_ì§€ì ìˆ˜"] = 0
            out.append(r)
            continue

        for region in ["1ì§€ì—­", "2ì§€ì—­", "3ì§€ì—­"]:
            sub = df[df["_ì§€ì—­"] == region]
            r[f"{region}_ì§€ì ìˆ˜"] = site.loc[sub.index].nunique() if site is not None else len(sub)
            r[f"{region}_ìµœê³ "] = None if sub[item].isna().all() else float(sub[item].max())
            ex = sub[sub.apply(lambda x: is_exceed(x, item, region), axis=1)]
            r[f"{region}_ìš°ë ¤ì´ˆê³¼_ì§€ì ìˆ˜"] = site.loc[ex.index].nunique() if site is not None else len(ex)

        out.append(r)

    return pd.DataFrame(out).where(pd.notna, None)

# =========================
# í™ˆ
# =========================
@app.route("/")
def home():
    return render_template_string("""
    <h1>ğŸ“Š Data Hub</h1>
    <ul>
    {% for k, ds in datasets.items() %}
      <li>
        <b>{{ ds.name }}</b><br>
        <a href="/dataset/{{k}}">ì›ë³¸</a> |
        <a href="/dataset/{{k}}/analysis">ë¶„ì„</a> |
        <a href="/dataset/{{k}}/log">ë¡œê·¸</a>
      </li>
    {% endfor %}
    </ul>
    """, datasets=DATASETS)

# =========================
# ì›ë³¸
# =========================
@app.route("/dataset/<dataset_id>")
def dataset_detail(dataset_id):
    df = normalize_columns(read_csv_safe(os.path.join(DATA_DIR, DATASETS[dataset_id]["file"])))
    return render_template_string("""
    <a href="/">ğŸ  Data Hub í™ˆìœ¼ë¡œ</a>
    <h2>ì›ë³¸ ë°ì´í„°</h2>
    {{ table|safe }}
    """, table=df.to_html(index=False))

# =========================
# ë¶„ì„
# =========================
@app.route("/dataset/<dataset_id>/analysis")
def dataset_analysis(dataset_id):
    df = normalize_columns(read_csv_safe(os.path.join(DATA_DIR, DATASETS[dataset_id]["file"])))

    survey_col = get_survey_column(df)
    df["_ì¡°ì‚¬"] = df[survey_col].apply(normalize_survey_type)
    df["_ì§€ì—­"] = df["ì§€ëª©(1/2/3)"].apply(normalize_region)

    all_items = list(STANDARDS["1ì§€ì—­"]["ìš°ë ¤ê¸°ì¤€"].keys())
    for c in all_items:
        if c in df.columns:
            df[c] = normalize_numeric_series(df[c])

    selected = request.args.getlist("items")
    use_items = selected if selected else all_items

    df_A = df[df["_ì¡°ì‚¬"] == "A"]
    df_B = df[df["_ì¡°ì‚¬"] == "B"]

    A = analyze_dataset(df_A, use_items)
    B = analyze_dataset(df_B, use_items)

    return render_template_string("""
    <a href="/">ğŸ  Data Hub í™ˆìœ¼ë¡œ</a>
    <h2>ğŸ“Š ë¶„ì„</h2>

    <button type="button" onclick="selectAllItems()">ì „ì²´ì„ íƒ</button>
    <button type="button" onclick="clearAllItems()">ì „ì²´ì„ íƒí•´ì œ</button>

    <form method="get">
      <table border="1" cellpadding="8">
        <tr>
          {% for g in ITEM_GROUPS.keys() %}
            <th>{{ g }}</th>
          {% endfor %}
        </tr>
        <tr>
          {% for g, items in ITEM_GROUPS.items() %}
            <td valign="top">
              {% for item in items %}
                <label>
                  <input type="checkbox" name="items" value="{{ item }}"
                    {% if item in selected %}checked{% endif %}>
                  {{ item }}
                </label><br>
              {% endfor %}
            </td>
          {% endfor %}
        </tr>
      </table>
      <br>
      <button>ì„ íƒ í•­ëª© ë³´ê¸°</button>
    </form>

    <form method="get" action="/dataset/{{ dataset_id }}/download">
      {% for item in selected %}
        <input type="hidden" name="items" value="{{ item }}">
      {% endfor %}
      <button type="submit">ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ</button>
    </form>

    <hr>
    <h3>ê°œí™©ì¡°ì‚¬</h3>
    {{ A|safe }}

    <h3>ì •ë°€ì¡°ì‚¬</h3>
    {{ B|safe }}

    <script>
    function selectAllItems() {
      document.querySelectorAll('input[name="items"]').forEach(cb => cb.checked = true);
    }
    function clearAllItems() {
      document.querySelectorAll('input[name="items"]').forEach(cb => cb.checked = false);
    }
    </script>
    """,
    ITEM_GROUPS=ITEM_GROUPS,
    selected=use_items,
    dataset_id=dataset_id,
    A=A.to_html(index=False),
    B=B.to_html(index=False)
    )

# =========================
# CSV ë‹¤ìš´ë¡œë“œ
# =========================
@app.route("/dataset/<dataset_id>/download")
def dataset_download(dataset_id):
    df = normalize_columns(read_csv_safe(os.path.join(DATA_DIR, DATASETS[dataset_id]["file"])))

    survey_col = get_survey_column(df)
    df["_ì¡°ì‚¬"] = df[survey_col].apply(normalize_survey_type)
    df["_ì§€ì—­"] = df["ì§€ëª©(1/2/3)"].apply(normalize_region)

    all_items = list(STANDARDS["1ì§€ì—­"]["ìš°ë ¤ê¸°ì¤€"].keys())
    for c in all_items:
        if c in df.columns:
            df[c] = normalize_numeric_series(df[c])

    selected = request.args.getlist("items")
    use_items = selected if selected else all_items

    df_A = df[df["_ì¡°ì‚¬"] == "A"]
    df_B = df[df["_ì¡°ì‚¬"] == "B"]

    result_A = analyze_dataset(df_A, use_items)
    result_B = analyze_dataset(df_B, use_items)

    result_A.insert(0, "ì¡°ì‚¬êµ¬ë¶„", "ê°œí™©(A)")
    result_B.insert(0, "ì¡°ì‚¬êµ¬ë¶„", "ì •ë°€(B)")

    final_df = pd.concat([result_A, result_B], ignore_index=True)
    csv_data = final_df.to_csv(index=False, encoding="utf-8-sig")

    return Response(
        csv_data,
        mimetype="text/csv; charset=utf-8",
        headers={
            "Content-Disposition": f"attachment; filename={dataset_id}_analysis.csv"
        }
    )


# =========================
# ë¡œê·¸
# =========================
@app.route("/dataset/<dataset_id>/log")
def dataset_log(dataset_id):
    df = normalize_columns(read_csv_safe(os.path.join(DATA_DIR, DATASETS[dataset_id]["file"])))
    df["_ì§€ì—­"] = df["ì§€ëª©(1/2/3)"].apply(normalize_region)
    fail = df[df["_ì§€ì—­"].isna()]

    return render_template_string("""
    <a href="/">ğŸ  Data Hub í™ˆìœ¼ë¡œ</a>
    <h2>âš  ë¡œê·¸ (ì§€ì—­ ë§¤ì¹­ ì‹¤íŒ¨)</h2>
    {% if t %}
      {{ t|safe }}
    {% else %}
      <p>ë¬¸ì œ ì—†ìŒ</p>
    {% endif %}
    """,
    t=fail[["ì§€ëª©(1/2/3)"]].drop_duplicates().to_html(index=False)
      if not fail.empty else None
    )

# =========================
# ì‹¤í–‰
# =========================
if __name__ == "__main__":
    app.run(debug=True)
