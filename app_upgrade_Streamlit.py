import streamlit as st
import pandas as pd
import os
import json
from io import BytesIO
from datetime import datetime

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ğŸ“Š Data Hub", layout="wide")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
META_FILE = os.path.join(BASE_DIR, "datasets.json")
os.makedirs(DATA_DIR, exist_ok=True)

# =========================
# í•­ëª© ê·¸ë£¹ (ë„ë©”ì¸ ì •ì˜)
# =========================
ITEM_GROUPS = {
    "ì¤‘ê¸ˆì†": ["Cd(mg/kg)", "Cu(mg/kg)", "As(mg/kg)", "Hg(mg/kg)",
            "Pb(mg/kg)", "Cr6+(mg/kg)", "Zn(mg/kg)", "Ni(mg/kg)"],
    "ìœ ë¥˜": ["Benzene", "Toluene", "Ethylbenzene", "Xylene", "TPH"],
    "ìœ ê¸°ìš©ì œ": ["TCE", "PCE", "1,2DCA (1,2-ë””í´ë¡œë¡œì—íƒ„)"],
    "ê¸°íƒ€": ["F(mg/kg)", "PCBs(mg/kg)", "CN(mg/kg)",
            "Phenol(mg/kg)", "Pentachlorophenol(mg/kg)", "Dioxin", "pH"]
}
ALL_ITEMS = [i for g in ITEM_GROUPS.values() for i in g]

# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def load_datasets():
    if os.path.exists(META_FILE):
        with open(META_FILE, encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_datasets(d):
    with open(META_FILE, "w", encoding="utf-8") as f:
        json.dump(d, f, ensure_ascii=False, indent=2)

def read_table(path):
    if path.endswith(".xlsx"):
        return pd.read_excel(path)
    try:
        return pd.read_csv(path, encoding="utf-8")
    except:
        return pd.read_csv(path, encoding="cp949")

def normalize_numeric_series(s):
    return pd.to_numeric(
        s.astype(str).str.replace(r"[^0-9eE\.\+\-]", "", regex=True),
        errors="coerce"
    )

def get_survey_column(df):
    for c in df.columns:
        if "ì¡°ì‚¬" in c:
            return c
    return None

def get_region_column(df):
    for c in df.columns:
        if "ì§€ëª©" in c or "ì§€ì—­" in c:
            return c
    return None

def normalize_survey_type(v):
    if pd.isna(v): return None
    if "ê°œí™©" in str(v): return "A"
    if "ì •ë°€" in str(v) or "ìƒì„¸" in str(v): return "B"
    return None

def normalize_region(v):
    if pd.isna(v): return None
    if "1" in str(v): return "1ì§€ì—­"
    if "2" in str(v): return "2ì§€ì—­"
    if "3" in str(v): return "3ì§€ì—­"
    return None

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 1: ë°ì´í„° ê´€ë¦¬
# =========================
def render_dataset_manager():
    st.sidebar.title("ğŸ—‚ ë°ì´í„° ê´€ë¦¬")
    datasets = load_datasets()

    # â• ì—…ë¡œë“œ
    st.sidebar.subheader("â• ë°ì´í„° ì¶”ê°€")
    uploaded = st.sidebar.file_uploader("CSV / XLSX ì—…ë¡œë“œ", type=["csv", "xlsx"])
    if uploaded:
        name = st.sidebar.text_input("ë°ì´í„° ì´ë¦„", uploaded.name)
        if st.sidebar.button("ì—…ë¡œë“œ ì €ì¥"):
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            fname = f"{ts}{os.path.splitext(uploaded.name)[1]}"
            with open(os.path.join(DATA_DIR, fname), "wb") as f:
                f.write(uploaded.getbuffer())
            datasets[ts] = {"name": name, "file": fname}
            save_datasets(datasets)
            st.experimental_rerun()

    # âŒ ì‚­ì œ
    st.sidebar.subheader("âŒ ë°ì´í„° ì‚­ì œ")
    if datasets:
        did = st.sidebar.selectbox(
            "ì‚­ì œ ëŒ€ìƒ",
            list(datasets.keys()),
            format_func=lambda k: datasets[k]["name"]
        )
        if st.sidebar.checkbox("âš  ì •ë§ ì‚­ì œ"):
            if st.sidebar.button("ì‚­ì œ ì‹¤í–‰"):
                try:
                    os.remove(os.path.join(DATA_DIR, datasets[did]["file"]))
                except:
                    pass
                datasets.pop(did)
                save_datasets(datasets)
                st.experimental_rerun()

    return datasets

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 2: ë°ì´í„° ì„ íƒ
# =========================
def render_dataset_selector(datasets):
    if not datasets:
        st.info("ğŸ“‚ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    return st.selectbox(
        "ğŸ“ ë°ì´í„° ì„ íƒ",
        list(datasets.keys()),
        format_func=lambda k: datasets[k]["name"]
    )

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 3: ì „ì²˜ë¦¬
# =========================
def preprocess_dataframe(df):
    survey_col = get_survey_column(df)
    df["_ì¡°ì‚¬"] = "A" if survey_col is None else df[survey_col].apply(normalize_survey_type)

    region_col = get_region_column(df)
    if region_col is None:
        st.error("âŒ ì§€ì—­ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    df["_ì§€ì—­"] = df[region_col].apply(normalize_region)

    for c in ALL_ITEMS:
        if c in df.columns:
            df[c] = normalize_numeric_series(df[c])

    return df

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 4: ë¶„ì„ í•­ëª© ì„ íƒ
# =========================
def render_item_selector():
    st.subheader("âœ… ë¶„ì„ í•­ëª© ì„ íƒ")

    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ”˜ ì „ì²´ ì„ íƒ"):
            for i in ALL_ITEMS:
                st.session_state[i] = True
    with c2:
        if st.button("â­• ì „ì²´ í•´ì œ"):
            for i in ALL_ITEMS:
                st.session_state[i] = False

    selected = []
    cols = st.columns(len(ITEM_GROUPS))
    for col, (g, items) in zip(cols, ITEM_GROUPS.items()):
        with col:
            st.markdown(f"**{g}**")
            for i in items:
                if st.checkbox(i, key=i):
                    selected.append(i)

    if not selected:
        st.warning("âš  í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    return selected

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 5: ë¶„ì„
# =========================
def analyze_dataset(df, items):
    out = []
    for item in items:
        r = {"í•­ëª©": item}
        for region in ["1ì§€ì—­", "2ì§€ì—­", "3ì§€ì—­"]:
            sub = df[df["_ì§€ì—­"] == region]
            r[f"{region}_ì§€ì ìˆ˜"] = len(sub)
            r[f"{region}_ìµœê³ "] = (
                float(sub[item].max())
                if item in sub.columns and not sub[item].isna().all()
                else None
            )
        out.append(r)
    return pd.DataFrame(out)

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 6: ê²°ê³¼ í‘œì‹œ
# =========================
def render_analysis_result(A, B):
    st.subheader("ğŸ“Š ê°œí™©ì¡°ì‚¬")
    st.dataframe(A, use_container_width=True)
    st.subheader("ğŸ“Š ì •ë°€ì¡°ì‚¬")
    st.dataframe(B, use_container_width=True)

# =========================
# ğŸ§© ì»´í¬ë„ŒíŠ¸ 7: ë‹¤ìš´ë¡œë“œ
# =========================
def render_xlsx_download(A, B, dataset_id):
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        A.to_excel(writer, index=False, sheet_name="ê°œí™©(A)")
        B.to_excel(writer, index=False, sheet_name="ì •ë°€(B)")

    st.download_button(
        "ğŸ“¥ XLSX ë‹¤ìš´ë¡œë“œ",
        data=buffer.getvalue(),
        file_name=f"{dataset_id}_analysis.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# =========================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# =========================
def main():
    st.title("ğŸ“Š Streamlit Data Hub")

    datasets = render_dataset_manager()
    dataset_id = render_dataset_selector(datasets)

    df = read_table(os.path.join(DATA_DIR, datasets[dataset_id]["file"]))
    st.subheader("ğŸ“„ ì›ë³¸ ë°ì´í„°")
    st.dataframe(df, use_container_width=True)

    df = preprocess_dataframe(df)
    selected_items = render_item_selector()

    A = analyze_dataset(df[df["_ì¡°ì‚¬"] == "A"], selected_items)
    B = analyze_dataset(df[df["_ì¡°ì‚¬"] == "B"], selected_items)

    render_analysis_result(A, B)
    render_xlsx_download(A, B, dataset_id)

main()
